{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c8fadef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a14572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_feature_analysis(audio_file):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "    # Extract MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "\n",
    "    # Extract F0 (fundamental frequency)\n",
    "    f0, voiced_flag, voiced_probs = librosa.pyin(y, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'))\n",
    "\n",
    "    # Extract onsets\n",
    "    onset_frames = librosa.onset.onset_detect(y=y, sr=sr)\n",
    "\n",
    "    # Extract beat frames\n",
    "    beat_frames = librosa.beat.beat_track(y, sr=sr)\n",
    "\n",
    "    # Plot MFCCs\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(librosa.power_to_db(mfccs, ref=np.max), y_axis='mel', x_axis='time')\n",
    "    plt.title('MFCCs')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot F0\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    times = librosa.times_like(f0)\n",
    "    plt.plot(times, f0, label='F0 (fundamental frequency)', color='b')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.title('Fundamental Frequency (F0)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot onsets\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    onset_times = librosa.times_like(onset_frames, sr=sr)\n",
    "    plt.plot(onset_times, onset_frames, label='Onsets', color='r', marker='o', linestyle='None')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Onset Frames')\n",
    "    plt.title('Onsets')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot beat tracking\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    beat_times = librosa.times_like(beat_frames, sr=sr)\n",
    "    plt.plot(beat_times, beat_frames, label='Beats', color='g', marker='o', linestyle='None')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Beat Frames')\n",
    "    plt.title('Beat Tracking')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "228f2d42",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "beat_track() takes 0 positional arguments but 1 positional argument (and 1 keyword-only argument) were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m audio_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/gcportable/Documents/GitHub/gawayneLessons/files/Zaini - Wherever you would call me - TRIM.wav\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m audio_feature_analysis(audio_file_path)\n",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m, in \u001b[0;36maudio_feature_analysis\u001b[0;34m(audio_file)\u001b[0m\n\u001b[1;32m     12\u001b[0m onset_frames \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39monset\u001b[38;5;241m.\u001b[39monset_detect(y\u001b[38;5;241m=\u001b[39my, sr\u001b[38;5;241m=\u001b[39msr)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Extract beat frames\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m beat_frames \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mbeat\u001b[38;5;241m.\u001b[39mbeat_track(y, sr\u001b[38;5;241m=\u001b[39msr)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Plot MFCCs\u001b[39;00m\n\u001b[1;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: beat_track() takes 0 positional arguments but 1 positional argument (and 1 keyword-only argument) were given"
     ]
    }
   ],
   "source": [
    "audio_file_path = '/Users/gcportable/Documents/GitHub/gawayneLessons/files/Zaini - Wherever you would call me - TRIM.wav'\n",
    "audio_feature_analysis(audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9a48c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x_/9x4q2pmj4rlctmx19n0hp1h00000gn/T/ipykernel_98879/501802382.py:8: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(audio_file)\n",
      "/Users/gcportable/anaconda3/lib/python3.11/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'your_audio_file_path.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/librosa/core/audio.py:175\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m __soundfile_load(path, offset, duration, dtype)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/librosa/core/audio.py:208\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     context \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mSoundFile(path)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[0;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(file, mode_int, closefd)\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[0;32m-> 1216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[1;32m   1218\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[0;31mLibsndfileError\u001b[0m: Error opening 'your_audio_file_path.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 114\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Example Usage:\u001b[39;00m\n\u001b[1;32m    113\u001b[0m audio_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myour_audio_file_path.wav\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 114\u001b[0m feature_analysis(audio_file_path)\n",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m, in \u001b[0;36mfeature_analysis\u001b[0;34m(audio_file)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeature_analysis\u001b[39m(audio_file):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Load audio file\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     y, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(audio_file)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# MFCC analysis\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     hop_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/librosa/core/audio.py:183\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n\u001b[1;32m    180\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    182\u001b[0m     )\n\u001b[0;32m--> 183\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m __audioread_load(path, offset, duration, dtype)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/librosa/util/decorators.py:59\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[1;32m     58\u001b[0m )\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/librosa/core/audio.py:239\u001b[0m, in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    236\u001b[0m     reader \u001b[38;5;241m=\u001b[39m path\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     reader \u001b[38;5;241m=\u001b[39m audioread\u001b[38;5;241m.\u001b[39maudio_open(path)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[1;32m    242\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m input_file\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/audioread/__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m BackendClass \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m BackendClass(path)\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/audioread/rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_audio_file_path.wav'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def feature_analysis(audio_file):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(audio_file)\n",
    "\n",
    "    # MFCC analysis\n",
    "    hop_length = 512\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=256)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    librosa.display.specshow(mfcc, x_axis='time')\n",
    "    plt.ylabel('MFCCs (1:256)')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    librosa.display.specshow(mfcc[1:12, :], x_axis='time')\n",
    "    plt.ylabel('MFCCs (2:13)')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.show()\n",
    "\n",
    "    # F0 analysis\n",
    "    audio_vals = analyze_audio(audio_file)\n",
    "    plot_audio_vals(audio_vals, audio_file, 'F0 Analysis', 'f0')\n",
    "\n",
    "    # Onsets analysis\n",
    "    get_onsets_wrapper(audio_file)\n",
    "\n",
    "    # Beat tracking\n",
    "    beat_tracking(audio_file)\n",
    "\n",
    "def analyze_audio(audio_path):\n",
    "    audio_vals = {}\n",
    "    y, sr = librosa.load(audio_path)\n",
    "    audio_vals['specCent'] = librosa.feature.spectral_centroid(y=y, sr=sr, n_fft=2048, hop_length=512, freq=None)\n",
    "    audio_vals['specBand'] = librosa.feature.spectral_bandwidth(y=y, sr=sr, n_fft=2048, hop_length=512, freq=None)\n",
    "    audio_vals['specContrast'] = librosa.feature.spectral_contrast(y=y, sr=sr, n_fft=2048, hop_length=512, freq=None)\n",
    "    audio_vals['specFlatness'] = librosa.feature.spectral_flatness(y=y)\n",
    "\n",
    "    audio_vals['f0'], _, _ = librosa.pyin(y, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'))\n",
    "    audio_vals['f0mean'] = np.nanmean(audio_vals['f0'])\n",
    "\n",
    "    return audio_vals\n",
    "\n",
    "def plot_audio_vals(audio_vals, audio_path, plot_title, data_name):\n",
    "    y, sr = librosa.load(audio_path)\n",
    "    times = librosa.times_like(audio_vals[data_name])\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "    fig, ax = plt.subplots()\n",
    "    img = librosa.display.specshow(D, x_axis='time', y_axis='log', ax=ax)\n",
    "    ax.set(title=plot_title)\n",
    "    fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
    "    ax.plot(times, audio_vals[data_name], label=data_name, color='cyan', linewidth=3)\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "def get_onsets_wrapper(filename):\n",
    "    sig, sr = librosa.load(filename, mono=True, sr=None)\n",
    "    onset_frames = get_onsets_env(sig, sr)\n",
    "    print('Estimated onsets:')\n",
    "    print(librosa.frames_to_time(onset_frames, sr=sr))\n",
    "\n",
    "def get_onsets_env(sig, sr=44100):\n",
    "    o_env = librosa.onset.onset_strength(sig, sr=sr)\n",
    "    times = librosa.frames_to_time(np.arange(len(o_env)), sr=sr)\n",
    "    onset_frames = librosa.onset.onset_detect(onset_envelope=o_env, sr=sr)\n",
    "\n",
    "    D = np.abs(librosa.stft(sig, n_fft=4096))\n",
    "    plt.figure()\n",
    "    ax1 = plt.subplot(2, 1, 1)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(D, ref=np.max), hop_length=512, x_axis='time', y_axis='log')\n",
    "    plt.title('Estimated from Onset Envelope')\n",
    "    plt.subplot(2, 1, 2, sharex=ax1)\n",
    "    plt.plot(times, o_env, label='Onset strength')\n",
    "    plt.vlines(times[onset_frames], 0, o_env.max(), color='r', alpha=0.9, linestyle='--', label='Onsets')\n",
    "    plt.axis('tight')\n",
    "    plt.legend(frameon=True, framealpha=0.75)\n",
    "\n",
    "    return onset_frames\n",
    "\n",
    "def beat_tracking(filename):\n",
    "    y, sr = librosa.load(filename)\n",
    "    S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "    log_S = librosa.power_to_db(S, ref=np.max)\n",
    "    mfcc = librosa.feature.mfcc(S=log_S, n_mfcc=13)\n",
    "    delta_mfcc = librosa.feature.delta(mfcc)\n",
    "    delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
    "    M = np.vstack([mfcc, delta_mfcc, delta2_mfcc])\n",
    "\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "    C = librosa.feature.chroma_cqt(y=y_harmonic, sr=sr)\n",
    "\n",
    "    tempo, beats = librosa.beat.beat_track(y=y_percussive, sr=sr)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    librosa.display.specshow(M)\n",
    "    plt.title('MFCC-$\\Delta$-$\\Delta^2$')\n",
    "    plt.yticks(np.arange(0, M.shape[0], 13), ['MFCC', '$\\Delta$', '$\\Delta^2$'])\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    librosa.display.specshow(librosa.util.sync(C, beats, aggregate=np.median), y_axis='chroma')\n",
    "    plt.title('Beat-synchronous Chroma (median aggregation)')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "# Example Usage:\n",
    "audio_file_path = 'your_audio_file_path.wav'\n",
    "feature_analysis(audio_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c93a60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
